{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m%d %H:%M%S')\n",
    "    print(f'\\n======================================={nowtime}')\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangjl19/miniconda3/envs/torch_graph2_cpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-08-03 08:45:23.577810: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-03 08:45:23.620140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-03 08:45:24.278752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "MIN_FREQ = 30\n",
    "MAX_LEN = 200\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "df_train = pd.read_csv('/data/snlp/zhangjl/datas/ctr/eat_pytorch_datasets/imdb/train.tsv', \n",
    "                       sep='\\t', header=None, names=['label', 'text'])\n",
    "\n",
    "df_test = pd.read_csv('/data/snlp/zhangjl/datas/ctr/eat_pytorch_datasets/imdb/test.tsv', \n",
    "                       sep='\\t', header=None, names=['label', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "PAD_IDX, UNK_IDX = 0, 1\n",
    "special_symbols = ['', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(dfdata):\n",
    "    for text in dfdata['text']:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(df_train),\n",
    "    min_freq=MIN_FREQ,\n",
    "    # specials=special_symbols,\n",
    "    special_first=True\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is 8811\n",
      "vocab pre top 20 str ['the', '.', ',', 'and', 'a', 'of', 'to', \"'\", 'is', 'it', 'in', 'i', 'this', 'that', 's', 'was', 'as', 'for', 'with', 'movie']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab.set_default_index(UNK_IDX)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f'vocab size is {vocab_size}')\n",
    "\n",
    "# 查看前20 \n",
    "print(f'vocab pre top 20 str {vocab.get_itos()[:20]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 8, 39, 459, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# pad\n",
    "def pad(seq, max_length, pad_value = 0):\n",
    "    n = len(seq)\n",
    "    result = seq + [pad_value] * max_length\n",
    "    return result[:max_length]\n",
    "\n",
    "\n",
    "# code transfer\n",
    "def text_pipline(text):\n",
    "    words = tokenizer(text)\n",
    "    tokens = vocab(words)\n",
    "    result = pad(tokens, MAX_LEN, PAD_IDX)\n",
    "    return result\n",
    "\n",
    "print(text_pipline(\"this is an example\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.df['text'].iloc[index]\n",
    "        label = torch.tensor([self.df['label'].iloc[index]]).float()\n",
    "        tokens = torch.tensor(text_pipline(text)).int()\n",
    "        return tokens, label\n",
    "    \n",
    "ds_train = ImdbDataset(df_train)\n",
    "ds_test = ImdbDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=50, shuffle=True)\n",
    "dl_test = DataLoader(ds_test, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffb20b69370>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(8811, 3, padding_idx=0)\n",
      "  (conv): Sequential(\n",
      "    (conv_1): Conv1d(3, 16, kernel_size=(5,), stride=(1,))\n",
      "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu_1): ReLU()\n",
      "    (conv_2): Conv1d(16, 128, kernel_size=(2,), stride=(1,))\n",
      "    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu_2): ReLU()\n",
      "  )\n",
      "  (dense): Sequential(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear): Linear(in_features=6144, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, \n",
    "                                      embedding_dim=3,\n",
    "                                      padding_idx=0)\n",
    "        \n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module('conv_1', nn.Conv1d(in_channels=3, out_channels=16, kernel_size=5))\n",
    "        self.conv.add_module('pool_1', nn.MaxPool1d(kernel_size=2))\n",
    "        self.conv.add_module('relu_1', nn.ReLU())\n",
    "\n",
    "        self.conv.add_module('conv_2', nn.Conv1d(in_channels=16, out_channels=128, kernel_size=2))\n",
    "        self.conv.add_module('pool_2', nn.MaxPool1d(kernel_size=2))\n",
    "        self.conv.add_module('relu_2', nn.ReLU())\n",
    "\n",
    "\n",
    "        self.dense = nn.Sequential()\n",
    "        self.dense.add_module('flatten', nn.Flatten())\n",
    "        self.dense.add_module('linear', nn.Linear(6144, 1)) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).transpose(1, 2) # batch x seqlen x emblen -> batch x emblen x seqlen \n",
    "        x = self.conv(x)\n",
    "        y = self.dense(x)\n",
    "        return y\n",
    "net = Net()\n",
    "print(net)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-03 09:27:10\n",
      "test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(str(info)+\"\\n\")\n",
    "\n",
    "printlog('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, stage='train', metrics_dict=None,\n",
    "                 optimizer=None, lr_scheduler=None):\n",
    "        self.net, self.loss_fn, self.metrics_dict, self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer, self.lr_scheduler = optimizer, lr_scheduler\n",
    "\n",
    "    def __call__(self, features, labels):\n",
    "        # loss\n",
    "        preds = self.net(features)\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "    \n",
    "        # backward\n",
    "        if self.optimizer is not None and self.stage == 'train':\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # metrics\n",
    "        step_metrics = {self.stage+\"_\"+name:metric_fn(preds, labels).item() \n",
    "                        for name,metric_fn in self.metrics_dict.items()}\n",
    "        \n",
    "        return loss.item(), step_metrics\n",
    "    \n",
    "\n",
    "class EpochRunner:\n",
    "    def __init__(self,steprunner):\n",
    "        self.steprunner = steprunner\n",
    "        self.stage = steprunner.stage\n",
    "        self.steprunner.net.train() if self.stage==\"train\" else self.steprunner.net.eval()\n",
    "\n",
    "\n",
    "    def __call__(self,dataloader):\n",
    "        total_loss,step = 0,0\n",
    "        loop = tqdm(enumerate(dataloader), total =len(dataloader))\n",
    "        for i, batch in loop: \n",
    "            if self.stage==\"train\":\n",
    "                loss, step_metrics = self.steprunner(*batch)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    loss, step_metrics = self.steprunner(*batch)\n",
    "            step_log = dict({self.stage+\"_loss\":loss},**step_metrics)\n",
    "\n",
    "            total_loss += loss\n",
    "            step+=1\n",
    "            if i!=len(dataloader)-1:\n",
    "                loop.set_postfix(**step_log) # set_postfix 是 bar 后面的信息， set_description 是bar前面的信息\n",
    "            else:\n",
    "                epoch_loss = total_loss/step\n",
    "                epoch_metrics = {self.stage+\"_\"+name:metric_fn.compute().item() \n",
    "                                for name,metric_fn in self.steprunner.metrics_dict.items()}\n",
    "                epoch_log = dict({self.stage+\"_loss\":epoch_loss},**epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name,metric_fn in self.steprunner.metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "        return epoch_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class KerasModel(torch.nn.Module):\n",
    "    def __init__(self,net,loss_fn,metrics_dict=None,optimizer=None,lr_scheduler = None):\n",
    "        super().__init__()\n",
    "        self.history = {}\n",
    "        \n",
    "        self.net = net\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metrics_dict = nn.ModuleDict(metrics_dict) \n",
    "        \n",
    "        self.optimizer = optimizer if optimizer is not None else torch.optim.Adam(\n",
    "            self.parameters(), lr=1e-2)\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.net:\n",
    "            return self.net.forward(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def fit(self, train_data, val_data=None, epochs=10, ckpt_path='checkpoint.pt', \n",
    "            patience=5, monitor=\"val_loss\", mode=\"min\"):\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "            \n",
    "            # 1，train -------------------------------------------------  \n",
    "            train_step_runner = StepRunner(net = self.net,stage=\"train\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict),\n",
    "                    optimizer = self.optimizer, lr_scheduler = self.lr_scheduler)\n",
    "            train_epoch_runner = EpochRunner(train_step_runner)\n",
    "            train_metrics = train_epoch_runner(train_data)\n",
    "            \n",
    "            for name, metric in train_metrics.items():\n",
    "                self.history[name] = self.history.get(name, []) + [metric]\n",
    "\n",
    "            # 2，validate -------------------------------------------------\n",
    "            if val_data:\n",
    "                val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict))\n",
    "                val_epoch_runner = EpochRunner(val_step_runner)\n",
    "                with torch.no_grad():\n",
    "                    val_metrics = val_epoch_runner(val_data)\n",
    "                val_metrics[\"epoch\"] = epoch\n",
    "                for name, metric in val_metrics.items():\n",
    "                    self.history[name] = self.history.get(name, []) + [metric]\n",
    "            \n",
    "            # 3，early-stopping -------------------------------------------------\n",
    "            if not val_data:\n",
    "                continue\n",
    "            arr_scores = self.history[monitor]\n",
    "            best_score_idx = np.argmax(arr_scores) if mode==\"max\" else np.argmin(arr_scores)\n",
    "            if best_score_idx==len(arr_scores)-1:\n",
    "                torch.save(self.net.state_dict(),ckpt_path)\n",
    "                print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                     arr_scores[best_score_idx]),file=sys.stderr)\n",
    "            if len(arr_scores)-best_score_idx>patience:\n",
    "                print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "                    monitor,patience),file=sys.stderr)\n",
    "                break \n",
    "                \n",
    "        self.net.load_state_dict(torch.load(ckpt_path))  \n",
    "        return pd.DataFrame(self.history)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, val_data):\n",
    "        val_step_runner = StepRunner(net = self.net,stage=\"val\",\n",
    "                    loss_fn = self.loss_fn,metrics_dict=deepcopy(self.metrics_dict))\n",
    "        val_epoch_runner = EpochRunner(val_step_runner)\n",
    "        val_metrics = val_epoch_runner(val_data)\n",
    "        return val_metrics\n",
    "        \n",
    "       \n",
    "    @torch.no_grad()\n",
    "    def predict(self, dataloader):\n",
    "        self.net.eval()\n",
    "        result = torch.cat([self.forward(t[0]) for t in dataloader])\n",
    "        return result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics \n",
    "\n",
    "class Accuracy(torchmetrics.Accuracy):\n",
    "    def __init__(self, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        \n",
    "    def update(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        super().update(torch.sigmoid(preds),targets.long())\n",
    "            \n",
    "    def compute(self):\n",
    "        return super().compute()\n",
    "    \n",
    "net = Net() \n",
    "model = KerasModel(net,\n",
    "                  loss_fn = nn.BCEWithLogitsLoss(),\n",
    "                  optimizer= torch.optim.Adam(net.parameters(),lr = 0.01),  \n",
    "                  metrics_dict = {\"acc\":Accuracy(task='binary')}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:09\n",
      "Epoch 1 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 56.23it/s, train_acc=0.499, train_loss=0.703]\n",
      "100%|██████████| 100/100 [00:01<00:00, 74.09it/s, val_acc=0.512, val_loss=0.694]\n",
      "<<<<<< reach best val_acc : 0.5123999714851379 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:18\n",
      "Epoch 2 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 56.31it/s, train_acc=0.5, train_loss=0.693] \n",
      "100%|██████████| 100/100 [00:01<00:00, 77.35it/s, val_acc=0.51, val_loss=0.694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:26\n",
      "Epoch 3 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:06<00:00, 58.61it/s, train_acc=0.668, train_loss=0.595]\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.53it/s, val_acc=0.76, val_loss=0.496]\n",
      "<<<<<< reach best val_acc : 0.7598000168800354 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:34\n",
      "Epoch 4 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:06<00:00, 59.66it/s, train_acc=0.799, train_loss=0.448]\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.44it/s, val_acc=0.796, val_loss=0.443]\n",
      "<<<<<< reach best val_acc : 0.7961999773979187 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:42\n",
      "Epoch 5 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:06<00:00, 58.41it/s, train_acc=0.844, train_loss=0.366]\n",
      "100%|██████████| 100/100 [00:01<00:00, 72.81it/s, val_acc=0.805, val_loss=0.436]\n",
      "<<<<<< reach best val_acc : 0.8051999807357788 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:50\n",
      "Epoch 6 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:06<00:00, 57.52it/s, train_acc=0.87, train_loss=0.314]\n",
      "100%|██████████| 100/100 [00:01<00:00, 77.35it/s, val_acc=0.807, val_loss=0.435]\n",
      "<<<<<< reach best val_acc : 0.807200014591217 >>>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:17:58\n",
      "Epoch 7 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:06<00:00, 57.73it/s, train_acc=0.892, train_loss=0.273]\n",
      "100%|██████████| 100/100 [00:01<00:00, 78.88it/s, val_acc=0.803, val_loss=0.459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:18:07\n",
      "Epoch 8 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 55.53it/s, train_acc=0.908, train_loss=0.237]\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.46it/s, val_acc=0.8, val_loss=0.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2023-08-02 11:18:15\n",
      "Epoch 9 / 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 55.83it/s, train_acc=0.921, train_loss=0.209]\n",
      "100%|██████████| 100/100 [00:01<00:00, 72.36it/s, val_acc=0.799, val_loss=0.507]\n",
      "<<<<<< val_acc without improvement in 3 epoch, early stopping >>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703175</td>\n",
       "      <td>0.49930</td>\n",
       "      <td>0.693996</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.693388</td>\n",
       "      <td>0.49955</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.5098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594592</td>\n",
       "      <td>0.66825</td>\n",
       "      <td>0.496322</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448057</td>\n",
       "      <td>0.79850</td>\n",
       "      <td>0.443230</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366164</td>\n",
       "      <td>0.84435</td>\n",
       "      <td>0.436347</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.314394</td>\n",
       "      <td>0.86955</td>\n",
       "      <td>0.434860</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.272615</td>\n",
       "      <td>0.89180</td>\n",
       "      <td>0.458876</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.237346</td>\n",
       "      <td>0.90785</td>\n",
       "      <td>0.510217</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.209260</td>\n",
       "      <td>0.92125</td>\n",
       "      <td>0.507311</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  val_loss  val_acc  epoch\n",
       "0    0.703175    0.49930  0.693996   0.5124      1\n",
       "1    0.693388    0.49955  0.693694   0.5098      2\n",
       "2    0.594592    0.66825  0.496322   0.7598      3\n",
       "3    0.448057    0.79850  0.443230   0.7962      4\n",
       "4    0.366164    0.84435  0.436347   0.8052      5\n",
       "5    0.314394    0.86955  0.434860   0.8072      6\n",
       "6    0.272615    0.89180  0.458876   0.8034      7\n",
       "7    0.237346    0.90785  0.510217   0.7996      8\n",
       "8    0.209260    0.92125  0.507311   0.7986      9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dl_train,\n",
    "    val_data=dl_test,\n",
    "    epochs=10,\n",
    "    ckpt_path='checkpoint.pt',\n",
    "    patience=3,\n",
    "    monitor='val_acc',\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703175</td>\n",
       "      <td>0.49930</td>\n",
       "      <td>0.693996</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.693388</td>\n",
       "      <td>0.49955</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.5098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594592</td>\n",
       "      <td>0.66825</td>\n",
       "      <td>0.496322</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448057</td>\n",
       "      <td>0.79850</td>\n",
       "      <td>0.443230</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366164</td>\n",
       "      <td>0.84435</td>\n",
       "      <td>0.436347</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.314394</td>\n",
       "      <td>0.86955</td>\n",
       "      <td>0.434860</td>\n",
       "      <td>0.8072</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.272615</td>\n",
       "      <td>0.89180</td>\n",
       "      <td>0.458876</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.237346</td>\n",
       "      <td>0.90785</td>\n",
       "      <td>0.510217</td>\n",
       "      <td>0.7996</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.209260</td>\n",
       "      <td>0.92125</td>\n",
       "      <td>0.507311</td>\n",
       "      <td>0.7986</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_acc  val_loss  val_acc  epoch\n",
       "0    0.703175    0.49930  0.693996   0.5124      1\n",
       "1    0.693388    0.49955  0.693694   0.5098      2\n",
       "2    0.594592    0.66825  0.496322   0.7598      3\n",
       "3    0.448057    0.79850  0.443230   0.7962      4\n",
       "4    0.366164    0.84435  0.436347   0.8052      5\n",
       "5    0.314394    0.86955  0.434860   0.8072      6\n",
       "6    0.272615    0.89180  0.458876   0.8034      7\n",
       "7    0.237346    0.90785  0.510217   0.7996      8\n",
       "8    0.209260    0.92125  0.507311   0.7986      9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "\n",
    "history = model.history\n",
    "dfhistory = pd.DataFrame(history) \n",
    "dfhistory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9512],\n",
       "        [0.9304],\n",
       "        [0.9289],\n",
       "        ...,\n",
       "        [0.9141],\n",
       "        [0.4350],\n",
       "        [0.9366]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(net,dl):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        result = nn.Sigmoid()(torch.cat([net.forward(t[0]) for t in dl]))\n",
    "    return(result.data)\n",
    "\n",
    "y_pred_probs = predict(net,dl_test)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型权重已经被保存在了ckpt_path='checkpoint.pt'\n",
    "net_clone = Net()\n",
    "net_clone.load_state_dict(torch.load('checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_graph2_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
